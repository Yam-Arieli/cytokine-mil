{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cytokine Signaling Cascade Mapping via AB-MIL Dynamics\n",
    "\n",
    "This notebook runs the full experiment:\n",
    "1. Load config and data\n",
    "2. Stage 1 — pre-train the InstanceEncoder with cell-type supervision\n",
    "3. Stage 2 — train full AB-MIL (encoder frozen)\n",
    "4. Stage 3 (optional) — fine-tune jointly\n",
    "5. Dynamics analysis — learnability ranking, entropy, instance confidence\n",
    "6. Validation — seed stability, known-group checks\n",
    "\n",
    "Connect to the cluster kernel before running.\n",
    "All paths in `configs/default.yaml` point to cluster storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport yaml\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom torch.utils.data import DataLoader\n\nfrom cytokine_mil.data.label_encoder import CytokineLabel\nfrom cytokine_mil.data.dataset import PseudoTubeDataset, CellDataset\nfrom cytokine_mil.models.instance_encoder import InstanceEncoder\nfrom cytokine_mil.models.attention import AttentionModule\nfrom cytokine_mil.models.bag_classifier import BagClassifier\nfrom cytokine_mil.models.cytokine_abmil import CytokineABMIL\nfrom cytokine_mil.training.train_encoder import train_encoder\nfrom cytokine_mil.training.train_mil import train_mil\nfrom cytokine_mil.experiment_setup import (\n    build_stage1_manifest,\n    build_encoder,\n    build_mil_model,\n)\nfrom cytokine_mil.analysis.dynamics import (\n    aggregate_to_donor_level,\n    rank_cytokines_by_learnability,\n    compute_cytokine_entropy_summary,\n    compute_confusion_entropy_summary,\n    build_cell_type_confidence_matrix,\n)\nfrom cytokine_mil.analysis.validation import (\n    check_seed_stability,\n    check_functional_groupings,\n)"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Seed: 42\n"
     ]
    }
   ],
   "source": [
    "# --- Config ---\n",
    "with open(\"cytokines/cytokines-mil/configs/default.yaml\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = cfg[\"dynamics\"][\"random_seeds\"][0]\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest entries: 10920\n",
      "HVGs: 4000\n"
     ]
    }
   ],
   "source": [
    "MANIFEST_PATH = cfg[\"data\"][\"manifest_path\"]\n",
    "\n",
    "with open(MANIFEST_PATH) as f:\n",
    "    manifest = json.load(f)\n",
    "\n",
    "# Load HVG list (saved by preprocess_tubes.ipynb)\n",
    "HVG_PATH = str(Path(MANIFEST_PATH).parent / \"hvg_list.json\")\n",
    "with open(HVG_PATH) as f:\n",
    "    gene_names = json.load(f)\n",
    "\n",
    "print(f\"Manifest entries: {len(manifest)}\")\n",
    "print(f\"HVGs: {len(gene_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 91 (PBS at index 90)\n"
     ]
    }
   ],
   "source": [
    "# Label encoder — must be built once and saved for reproducibility\n",
    "LABEL_ENCODER_PATH = str(Path(MANIFEST_PATH).parent / \"label_encoder.json\")\n",
    "label_encoder = CytokineLabel().fit(manifest)\n",
    "label_encoder.save(LABEL_ENCODER_PATH)\n",
    "print(f\"Classes: {label_encoder.n_classes()} (PBS at index {label_encoder.encode('PBS')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Pseudo-tube dataset (Stage 2/3)\n# preload=True: loads all 10k tubes as sparse matrices at init (~8-10 GB).\n# Eliminates all disk I/O during training and dynamics logging.\ntube_dataset = PseudoTubeDataset(MANIFEST_PATH, label_encoder, gene_names=gene_names, preload=True)\nprint(f\"Tubes: {len(tube_dataset)}\")\n\n# --- Stage 1 manifest: one tube per cytokine, rotating donors ---\n# ~91 tubes × ~450 cells ≈ 40k cells ≈ 640 MB when preloaded.\nSTAGE1_MANIFEST_PATH = str(Path(MANIFEST_PATH).parent / \"manifest_stage1.json\")\n_stage1_manifest = build_stage1_manifest(manifest, save_path=STAGE1_MANIFEST_PATH)\n\n# preload=True: loads all tubes at init → in-memory shuffling, no disk I/O per batch\ncell_dataset = CellDataset(STAGE1_MANIFEST_PATH, gene_names=gene_names, preload=True)\nprint(f\"Cells: {len(cell_dataset)}\")\nprint(f\"Cell types: {cell_dataset.n_cell_types()}\")\n# Sanity check — run this before train_encoder\nprint(f\"NaN in X: {np.isnan(cell_dataset._X).any()}\")\nprint(f\"Inf in X: {np.isinf(cell_dataset._X).any()}\")\nprint(f\"X range: [{cell_dataset._X.min():.3f}, {cell_dataset._X.max():.3f}]\")\n\ncell_loader = DataLoader(cell_dataset, batch_size=256, shuffle=True, num_workers=0)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stage 1 — Encoder Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "encoder = build_encoder(\n    n_input_genes=len(gene_names),\n    n_cell_types=cell_dataset.n_cell_types(),\n    embed_dim=cfg[\"model\"][\"embedding_dim\"],\n)\n\nencoder = train_encoder(\n    encoder,\n    cell_loader,\n    # n_epochs=cfg[\"training\"][\"stage1_epochs\"],\n    n_epochs=16,\n    lr=cfg[\"training\"][\"lr\"],\n    momentum=cfg[\"training\"][\"momentum\"],\n    device=DEVICE,\n    verbose=True,\n)\n\ntorch.save(encoder.state_dict(), \"encoder_stage1.pt\")\nprint(\"Encoder saved.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stage 2 — MIL Training (encoder frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "mil_model = build_mil_model(\n    encoder,\n    embed_dim=cfg[\"model\"][\"embedding_dim\"],\n    attention_hidden_dim=cfg[\"model\"][\"attention_hidden_dim\"],\n    n_classes=cfg[\"model\"][\"n_classes\"],\n    encoder_frozen=True,\n)\n\ndynamics_stage2 = train_mil(\n    mil_model,\n    tube_dataset,\n    n_epochs=cfg[\"training\"][\"stage2_epochs\"],\n    lr=cfg[\"training\"][\"lr\"],\n    momentum=cfg[\"training\"][\"momentum\"],\n    lr_scheduler=cfg[\"training\"][\"lr_scheduler\"],\n    lr_warmup_epochs=cfg[\"training\"][\"lr_warmup_epochs\"],\n    log_every_n_epochs=cfg[\"dynamics\"][\"log_every_n_epochs\"],\n    device=DEVICE,\n    seed=SEED,\n    verbose=True,\n)\n\ntorch.save(mil_model.state_dict(), \"mil_stage2.pt\")\nprint(\"Stage 2 model saved.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stage 3 — Joint Fine-tuning (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mil_model.unfreeze_encoder()\n",
    "\n",
    "dynamics_stage3 = train_mil(\n",
    "    mil_model,\n",
    "    tube_dataset,\n",
    "    n_epochs=cfg[\"training\"][\"stage3_epochs\"],\n",
    "    lr=cfg[\"training\"][\"lr\"] * 0.1,  # lower LR for fine-tuning\n",
    "    momentum=cfg[\"training\"][\"momentum\"],\n",
    "    log_every_n_epochs=cfg[\"dynamics\"][\"log_every_n_epochs\"],\n",
    "    device=DEVICE,\n",
    "    seed=SEED,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "torch.save(mil_model.state_dict(), \"mil_stage3.pt\")\n",
    "print(\"Stage 3 model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dynamics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Use Stage 2 dynamics for primary analysis (encoder frozen = cleaner dynamics)\ndonor_traj = aggregate_to_donor_level(dynamics_stage2[\"records\"])\n\n# Learnability ranking (exclude PBS from biological interpretation)\nlearnability_result = rank_cytokines_by_learnability(donor_traj, exclude=[\"PBS\"])\nranking = learnability_result[\"ranking\"]\n\nprint(\"Cytokine learnability ranking\")\nprint(f\"Metric: {learnability_result['metric_description']}\")\nprint()\nfor i, (cyt, auc) in enumerate(ranking, 1):\n    print(f\"  {i:2d}. {cyt:20s}  AUC(mean_donor_p_correct_trajectory) = {auc:.3f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot learning curves for top-10 and bottom-10 cytokines\ntop10 = [r[0] for r in ranking[:10]]\nbot10 = [r[0] for r in ranking[-10:]]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\nfor ax, group, group_label in zip(\n    axes,\n    [top10, bot10],\n    [\"Top-10 (highest AUC — learned earliest)\", \"Bottom-10 (lowest AUC — learned latest)\"],\n):\n    for cyt in group:\n        donor_curves = list(donor_traj[cyt].values())\n        mean_curve = np.mean(donor_curves, axis=0)\n        epochs = dynamics_stage2[\"logged_epochs\"]\n        ax.plot(epochs, mean_curve, label=cyt, alpha=0.8)\n    ax.set_xlabel(\"Epoch\")\n    ax.set_ylabel(\"P(Y_correct | t) — softmax probability of correct cytokine class\")\n    ax.set_title(group_label)\n    ax.legend(fontsize=7, ncol=2)\n\nplt.suptitle(\n    \"Stage 2 learning curves\\n\"\n    \"Metric: mean p_correct_trajectory(t), aggregated to donor level \"\n    \"(median across pseudo-tubes per donor, then mean across donors)\",\n    fontsize=9,\n)\nplt.tight_layout()\nplt.savefig(\"learning_curves.png\", dpi=150)\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Attention entropy summary\nentropy_result = compute_cytokine_entropy_summary(dynamics_stage2[\"records\"])\nentropy_summary = entropy_result[\"summary\"]\n\n# Sort by mean entropy (low=focused, high=pleiotropic)\nentropy_sorted = sorted(entropy_summary.items(), key=lambda x: x[1][\"mean_entropy\"])\n\nprint(\"Cytokine attention entropy summary\")\nprint(f\"Metric: {entropy_result['metric_description']}\")\nprint()\nfor cyt, stats in entropy_sorted:\n    print(f\"  {cyt:20s}  mean_entropy = {stats['mean_entropy']:.3f}  std = {stats['std_entropy']:.3f}\")"
  },
  {
   "cell_type": "code",
   "source": "# Confusion entropy summary\nconfusion_result = compute_confusion_entropy_summary(\n    dynamics_stage2[\"confusion_entropy_trajectory\"], exclude=[\"PBS\"]\n)\n\nprint(\"Cytokine confusion entropy ranking\")\nprint(f\"Metric: {confusion_result['metric_description']}\")\nprint()\nfor cyt, auc in confusion_result[\"ranking\"]:\n    print(f\"  {cyt:20s}  AUC(confusion_entropy_trajectory) = {auc:.3f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with multiple seeds to assess stability. See config random_seeds.\n"
     ]
    }
   ],
   "source": [
    "# Seed stability — run with all three seeds from config\n",
    "# NOTE: Pre-register your directional predictions BEFORE looking at these results.\n",
    "\n",
    "all_dynamics = [dynamics_stage2]  # Add dynamics from other seeds here\n",
    "\n",
    "# Example: to run with additional seeds, re-run train_mil with seed=123 and seed=7\n",
    "# and append to all_dynamics.\n",
    "\n",
    "if len(all_dynamics) > 1:\n",
    "    stability = check_seed_stability(all_dynamics, exclude=[\"PBS\"])\n",
    "    print(f\"Mean Spearman rho across seeds: {stability['mean_rho']:.3f}\")\n",
    "    print(f\"Stable ordering: {stability['stable']}\")\n",
    "else:\n",
    "    print(\"Run with multiple seeds to assess stability. See config random_seeds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IL-2_IL-15_family:\n",
      "  members_found: ['IL-2', 'IL-15']\n",
      "  within_auc_std: 2.9490238849151282\n",
      "  between_auc_std: 13.025140774941931\n",
      "  passes: True\n",
      "\n",
      "type_I_IFN:\n",
      "  error: fewer than 2 members found: ['IFN-beta']\n"
     ]
    }
   ],
   "source": [
    "# Known functional groupings (IL-2 / IL-15 should be similar)\n",
    "known_groups = {\n",
    "    \"IL-2_IL-15_family\": [\"IL-2\", \"IL-15\"],\n",
    "    \"type_I_IFN\": [\"IFN-alpha\", \"IFN-beta\"],  # adjust to actual cytokine names\n",
    "}\n",
    "\n",
    "grouping_result = check_functional_groupings(donor_traj, known_groups)\n",
    "for group, result in grouping_result.items():\n",
    "    print(f\"\\n{group}:\")\n",
    "    for k, v in result.items():\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "donor_traj_s3 = aggregate_to_donor_level(dynamics_stage3[\"records\"])\nresult_s3 = rank_cytokines_by_learnability(donor_traj_s3, exclude=[\"PBS\"])\nranking_s3 = result_s3[\"ranking\"]\n\nfrom cytokine_mil.analysis.validation import check_seed_stability\n# Reuse seed stability check to compare two orderings (Stage 2 vs Stage 3)\nstability_s2_s3 = check_seed_stability(\n    [dynamics_stage2, dynamics_stage3], exclude=[\"PBS\"]\n)\nprint(\"Stage 2 vs Stage 3 ranking correlation\")\nprint(\n    \"Metric: Spearman rho between cytokine learnability rankings \"\n    \"(AUC of donor-level p_correct_trajectory, median per donor, mean across donors)\"\n)\nprint(f\"  Spearman rho = {stability_s2_s3['mean_rho']:.3f}\")\nprint(f\"  Stable across stages (rho > 0.7): {stability_s2_s3['stable']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_traj_s3 = aggregate_to_donor_level(dynamics_stage3[\"records\"])\n",
    "ranking_s3 = rank_cytokines_by_learnability(donor_traj_s3, exclude=[\"PBS\"])\n",
    "\n",
    "from cytokine_mil.analysis.validation import check_seed_stability\n",
    "# Reuse seed stability to compare two orderings (Stage 2 vs 3)\n",
    "stability_s2_s3 = check_seed_stability(\n",
    "    [dynamics_stage2, dynamics_stage3], exclude=[\"PBS\"]\n",
    ")\n",
    "print(f\"Stage2 vs Stage3 ranking correlation: {stability_s2_s3['mean_rho']:.3f}\")\n",
    "print(f\"Stable across stages: {stability_s2_s3['stable']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (biovenv)",
   "language": "python",
   "name": "biovenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}