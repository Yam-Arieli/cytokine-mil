{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cytokine Signaling Cascade Mapping via AB-MIL Dynamics\n",
    "\n",
    "This notebook runs the full experiment:\n",
    "1. Load config and data\n",
    "2. Stage 1 — pre-train the InstanceEncoder with cell-type supervision\n",
    "3. Stage 2 — train full AB-MIL (encoder frozen)\n",
    "4. Stage 3 (optional) — fine-tune jointly\n",
    "5. Dynamics analysis — learnability ranking, entropy, instance confidence\n",
    "6. Validation — seed stability, known-group checks\n",
    "\n",
    "Connect to the cluster kernel before running.\n",
    "All paths in `configs/default.yaml` point to cluster storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from cytokine_mil.data.label_encoder import CytokineLabel\n",
    "from cytokine_mil.data.dataset import PseudoTubeDataset, CellDataset\n",
    "from cytokine_mil.models.instance_encoder import InstanceEncoder\n",
    "from cytokine_mil.models.attention import AttentionModule\n",
    "from cytokine_mil.models.bag_classifier import BagClassifier\n",
    "from cytokine_mil.models.cytokine_abmil import CytokineABMIL\n",
    "from cytokine_mil.training.train_encoder import train_encoder\n",
    "from cytokine_mil.training.train_mil import train_mil\n",
    "from cytokine_mil.analysis.dynamics import (\n",
    "    aggregate_to_donor_level,\n",
    "    rank_cytokines_by_learnability,\n",
    "    compute_cytokine_entropy_summary,\n",
    ")\n",
    "from cytokine_mil.analysis.validation import (\n",
    "    check_seed_stability,\n",
    "    check_functional_groupings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config ---\n",
    "with open(\"configs/default.yaml\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = cfg[\"dynamics\"][\"random_seeds\"][0]\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MANIFEST_PATH = cfg[\"data\"][\"manifest_path\"]\n",
    "\n",
    "with open(MANIFEST_PATH) as f:\n",
    "    manifest = json.load(f)\n",
    "\n",
    "# Load HVG list (saved by build_pseudotubes.py)\n",
    "HVG_PATH = str(Path(MANIFEST_PATH).parent / \"hvg_list.json\")\n",
    "with open(HVG_PATH) as f:\n",
    "    gene_names = json.load(f)\n",
    "\n",
    "print(f\"Manifest entries: {len(manifest)}\")\n",
    "print(f\"HVGs: {len(gene_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoder — must be built once and saved for reproducibility\n",
    "LABEL_ENCODER_PATH = str(Path(MANIFEST_PATH).parent / \"label_encoder.json\")\n",
    "label_encoder = CytokineLabel().fit(manifest)\n",
    "label_encoder.save(LABEL_ENCODER_PATH)\n",
    "print(f\"Classes: {label_encoder.n_classes()} (PBS at index {label_encoder.encode('PBS')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-tube dataset (Stage 2/3)\n",
    "tube_dataset = PseudoTubeDataset(MANIFEST_PATH, label_encoder, gene_names=gene_names)\n",
    "print(f\"Tubes: {len(tube_dataset)}\")\n",
    "\n",
    "# Cell dataset (Stage 1 encoder pre-training)\n",
    "cell_dataset = CellDataset(MANIFEST_PATH, gene_names=gene_names)\n",
    "print(f\"Cells: {len(cell_dataset)}\")\n",
    "print(f\"Cell types: {cell_dataset.n_cell_types()}\")\n",
    "\n",
    "cell_loader = DataLoader(cell_dataset, batch_size=256, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stage 1 — Encoder Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = InstanceEncoder(\n",
    "    input_dim=len(gene_names),\n",
    "    embed_dim=cfg[\"model\"][\"embedding_dim\"],\n",
    "    n_cell_types=cell_dataset.n_cell_types(),\n",
    ")\n",
    "\n",
    "encoder = train_encoder(\n",
    "    encoder,\n",
    "    cell_loader,\n",
    "    n_epochs=cfg[\"training\"][\"stage1_epochs\"],\n",
    "    lr=cfg[\"training\"][\"lr\"],\n",
    "    momentum=cfg[\"training\"][\"momentum\"],\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "torch.save(encoder.state_dict(), \"encoder_stage1.pt\")\n",
    "print(\"Encoder saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stage 2 — MIL Training (encoder frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = AttentionModule(\n",
    "    embed_dim=cfg[\"model\"][\"embedding_dim\"],\n",
    "    attention_hidden_dim=cfg[\"model\"][\"attention_hidden_dim\"],\n",
    ")\n",
    "classifier = BagClassifier(\n",
    "    embed_dim=cfg[\"model\"][\"embedding_dim\"],\n",
    "    n_classes=cfg[\"model\"][\"n_classes\"],\n",
    ")\n",
    "mil_model = CytokineABMIL(encoder, attention, classifier, encoder_frozen=True)\n",
    "\n",
    "dynamics_stage2 = train_mil(\n",
    "    mil_model,\n",
    "    tube_dataset,\n",
    "    n_epochs=cfg[\"training\"][\"stage2_epochs\"],\n",
    "    lr=cfg[\"training\"][\"lr\"],\n",
    "    momentum=cfg[\"training\"][\"momentum\"],\n",
    "    lr_scheduler=cfg[\"training\"][\"lr_scheduler\"],\n",
    "    lr_warmup_epochs=cfg[\"training\"][\"lr_warmup_epochs\"],\n",
    "    log_every_n_epochs=cfg[\"dynamics\"][\"log_every_n_epochs\"],\n",
    "    device=DEVICE,\n",
    "    seed=SEED,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "torch.save(mil_model.state_dict(), \"mil_stage2.pt\")\n",
    "print(\"Stage 2 model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stage 3 — Joint Fine-tuning (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mil_model.unfreeze_encoder()\n",
    "\n",
    "dynamics_stage3 = train_mil(\n",
    "    mil_model,\n",
    "    tube_dataset,\n",
    "    n_epochs=cfg[\"training\"][\"stage3_epochs\"],\n",
    "    lr=cfg[\"training\"][\"lr\"] * 0.1,  # lower LR for fine-tuning\n",
    "    momentum=cfg[\"training\"][\"momentum\"],\n",
    "    log_every_n_epochs=cfg[\"dynamics\"][\"log_every_n_epochs\"],\n",
    "    device=DEVICE,\n",
    "    seed=SEED,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "torch.save(mil_model.state_dict(), \"mil_stage3.pt\")\n",
    "print(\"Stage 3 model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dynamics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Stage 2 dynamics for primary analysis (encoder frozen = cleaner dynamics)\n",
    "donor_traj = aggregate_to_donor_level(dynamics_stage2[\"records\"])\n",
    "\n",
    "# Learnability ranking (exclude PBS from biological interpretation)\n",
    "ranking = rank_cytokines_by_learnability(donor_traj, exclude=[\"PBS\"])\n",
    "\n",
    "print(\"Cytokine learnability ranking (highest AUC = learned earliest):\")\n",
    "for i, (cyt, auc) in enumerate(ranking, 1):\n",
    "    print(f\"  {i:2d}. {cyt:20s}  AUC={auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves for top-10 and bottom-10 cytokines\n",
    "top10 = [r[0] for r in ranking[:10]]\n",
    "bot10 = [r[0] for r in ranking[-10:]]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "for ax, group, title in zip(axes, [top10, bot10], [\"Top-10 (earliest)\", \"Bottom-10 (latest)\"]):\n",
    "    for cyt in group:\n",
    "        # Mean across donors\n",
    "        donor_curves = list(donor_traj[cyt].values())\n",
    "        mean_curve = np.mean(donor_curves, axis=0)\n",
    "        epochs = dynamics_stage2[\"logged_epochs\"]\n",
    "        ax.plot(epochs, mean_curve, label=cyt, alpha=0.8)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"P(Y_correct)\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend(fontsize=7, ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"learning_curves.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention entropy summary\n",
    "entropy_summary = compute_cytokine_entropy_summary(dynamics_stage2[\"records\"])\n",
    "\n",
    "# Sort by mean entropy\n",
    "entropy_sorted = sorted(entropy_summary.items(), key=lambda x: x[1][\"mean\"])\n",
    "\n",
    "print(\"Attention entropy (low=focused, high=pleiotropic):\")\n",
    "for cyt, stats in entropy_sorted:\n",
    "    print(f\"  {cyt:20s}  mean={stats['mean']:.3f}  std={stats['std']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed stability — run with all three seeds from config\n",
    "# NOTE: Pre-register your directional predictions BEFORE looking at these results.\n",
    "\n",
    "all_dynamics = [dynamics_stage2]  # Add dynamics from other seeds here\n",
    "\n",
    "# Example: to run with additional seeds, re-run train_mil with seed=123 and seed=7\n",
    "# and append to all_dynamics.\n",
    "\n",
    "if len(all_dynamics) > 1:\n",
    "    stability = check_seed_stability(all_dynamics, exclude=[\"PBS\"])\n",
    "    print(f\"Mean Spearman rho across seeds: {stability['mean_rho']:.3f}\")\n",
    "    print(f\"Stable ordering: {stability['stable']}\")\n",
    "else:\n",
    "    print(\"Run with multiple seeds to assess stability. See config random_seeds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Known functional groupings (IL-2 / IL-15 should be similar)\n",
    "known_groups = {\n",
    "    \"IL-2_IL-15_family\": [\"IL-2\", \"IL-15\"],\n",
    "    \"type_I_IFN\": [\"IFN-alpha\", \"IFN-beta\"],  # adjust to actual cytokine names\n",
    "}\n",
    "\n",
    "grouping_result = check_functional_groupings(donor_traj, known_groups)\n",
    "for group, result in grouping_result.items():\n",
    "    print(f\"\\n{group}:\")\n",
    "    for k, v in result.items():\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Stage 2 vs Stage 3 Comparison\n",
    "\n",
    "If the learnability ordering is stable across Stage 2 and Stage 3, this is\n",
    "evidence that the dynamics signal is robust to encoder fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_traj_s3 = aggregate_to_donor_level(dynamics_stage3[\"records\"])\n",
    "ranking_s3 = rank_cytokines_by_learnability(donor_traj_s3, exclude=[\"PBS\"])\n",
    "\n",
    "from cytokine_mil.analysis.validation import check_seed_stability\n",
    "# Reuse seed stability to compare two orderings (Stage 2 vs 3)\n",
    "stability_s2_s3 = check_seed_stability(\n",
    "    [dynamics_stage2, dynamics_stage3], exclude=[\"PBS\"]\n",
    ")\n",
    "print(f\"Stage2 vs Stage3 ranking correlation: {stability_s2_s3['mean_rho']:.3f}\")\n",
    "print(f\"Stable across stages: {stability_s2_s3['stable']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
