{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cytokine Signaling Cascade Mapping via AB-MIL Dynamics\n",
    "\n",
    "This notebook runs the full experiment:\n",
    "1. Load config and data\n",
    "2. Stage 1 — pre-train the InstanceEncoder with cell-type supervision\n",
    "3. Stage 2 — train full AB-MIL (encoder frozen)\n",
    "4. Stage 3 (optional) — fine-tune jointly\n",
    "5. Dynamics analysis — learnability ranking, entropy, instance confidence\n",
    "6. Validation — seed stability, known-group checks\n",
    "\n",
    "Connect to the cluster kernel before running.\n",
    "All paths in `configs/default.yaml` point to cluster storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from cytokine_mil.data.label_encoder import CytokineLabel\n",
    "from cytokine_mil.data.dataset import PseudoTubeDataset, CellDataset\n",
    "from cytokine_mil.models.instance_encoder import InstanceEncoder\n",
    "from cytokine_mil.models.attention import AttentionModule\n",
    "from cytokine_mil.models.bag_classifier import BagClassifier\n",
    "from cytokine_mil.models.cytokine_abmil import CytokineABMIL\n",
    "from cytokine_mil.training.train_encoder import train_encoder\n",
    "from cytokine_mil.training.train_mil import train_mil\n",
    "from cytokine_mil.experiment_setup import (\n",
    "    build_stage1_manifest,\n",
    "    build_encoder,\n",
    "    build_mil_model,\n",
    ")\n",
    "from cytokine_mil.analysis.dynamics import (\n",
    "    aggregate_to_donor_level,\n",
    "    rank_cytokines_by_learnability,\n",
    "    compute_cytokine_entropy_summary,\n",
    "    compute_confusion_entropy_summary,\n",
    "    build_cell_type_confidence_matrix,\n",
    ")\n",
    "from cytokine_mil.analysis.validation import (\n",
    "    check_seed_stability,\n",
    "    check_functional_groupings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Seed: 42\n"
     ]
    }
   ],
   "source": [
    "# --- Config ---\n",
    "with open(\"cytokines/cytokines-mil/configs/default.yaml\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = cfg[\"dynamics\"][\"random_seeds\"][0]\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest entries: 10920\n",
      "HVGs: 4000\n"
     ]
    }
   ],
   "source": [
    "MANIFEST_PATH = cfg[\"data\"][\"manifest_path\"]\n",
    "\n",
    "with open(MANIFEST_PATH) as f:\n",
    "    manifest = json.load(f)\n",
    "\n",
    "# Load HVG list (saved by preprocess_tubes.ipynb)\n",
    "HVG_PATH = str(Path(MANIFEST_PATH).parent / \"hvg_list.json\")\n",
    "with open(HVG_PATH) as f:\n",
    "    gene_names = json.load(f)\n",
    "\n",
    "print(f\"Manifest entries: {len(manifest)}\")\n",
    "print(f\"HVGs: {len(gene_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 91 (PBS at index 90)\n"
     ]
    }
   ],
   "source": [
    "# Label encoder — must be built once and saved for reproducibility\n",
    "LABEL_ENCODER_PATH = str(Path(MANIFEST_PATH).parent / \"label_encoder.json\")\n",
    "label_encoder = CytokineLabel().fit(manifest)\n",
    "label_encoder.save(LABEL_ENCODER_PATH)\n",
    "print(f\"Classes: {label_encoder.n_classes()} (PBS at index {label_encoder.encode('PBS')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-tube dataset (Stage 2/3)\n",
    "# preload=True: loads all 10k tubes as sparse matrices at init (~8-10 GB).\n",
    "# Eliminates all disk I/O during training and dynamics logging.\n",
    "tube_dataset = PseudoTubeDataset(MANIFEST_PATH, label_encoder, gene_names=gene_names, preload=True)\n",
    "print(f\"Tubes: {len(tube_dataset)}\")\n",
    "\n",
    "# --- Stage 1 manifest: one tube per cytokine, rotating donors ---\n",
    "# ~91 tubes × ~450 cells ≈ 40k cells ≈ 640 MB when preloaded.\n",
    "STAGE1_MANIFEST_PATH = str(Path(MANIFEST_PATH).parent / \"manifest_stage1.json\")\n",
    "_stage1_manifest = build_stage1_manifest(manifest, save_path=STAGE1_MANIFEST_PATH)\n",
    "\n",
    "# preload=True: loads all tubes at init → in-memory shuffling, no disk I/O per batch\n",
    "cell_dataset = CellDataset(STAGE1_MANIFEST_PATH, gene_names=gene_names, preload=True)\n",
    "print(f\"Cells: {len(cell_dataset)}\")\n",
    "print(f\"Cell types: {cell_dataset.n_cell_types()}\")\n",
    "# Sanity check — run this before train_encoder\n",
    "print(f\"NaN in X: {np.isnan(cell_dataset._X).any()}\")\n",
    "print(f\"Inf in X: {np.isinf(cell_dataset._X).any()}\")\n",
    "print(f\"X range: [{cell_dataset._X.min():.3f}, {cell_dataset._X.max():.3f}]\")\n",
    "\n",
    "cell_loader = DataLoader(cell_dataset, batch_size=256, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stage 1 — Encoder Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = build_encoder(\n",
    "    n_input_genes=len(gene_names),\n",
    "    n_cell_types=cell_dataset.n_cell_types(),\n",
    "    embed_dim=cfg[\"model\"][\"embedding_dim\"],\n",
    ")\n",
    "\n",
    "encoder = train_encoder(\n",
    "    encoder,\n",
    "    cell_loader,\n",
    "    # n_epochs=cfg[\"training\"][\"stage1_epochs\"],\n",
    "    n_epochs=16,\n",
    "    lr=cfg[\"training\"][\"lr\"],\n",
    "    momentum=cfg[\"training\"][\"momentum\"],\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "torch.save(encoder.state_dict(), \"encoder_stage1.pt\")\n",
    "print(\"Encoder saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stage 2 — MIL Training (encoder frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mil_model = build_mil_model(\n",
    "    encoder,\n",
    "    embed_dim=cfg[\"model\"][\"embedding_dim\"],\n",
    "    attention_hidden_dim=cfg[\"model\"][\"attention_hidden_dim\"],\n",
    "    n_classes=cfg[\"model\"][\"n_classes\"],\n",
    "    encoder_frozen=True,\n",
    ")\n",
    "\n",
    "dynamics_stage2 = train_mil(\n",
    "    mil_model,\n",
    "    tube_dataset,\n",
    "    n_epochs=cfg[\"training\"][\"stage2_epochs\"],\n",
    "    lr=cfg[\"training\"][\"lr\"],\n",
    "    momentum=cfg[\"training\"][\"momentum\"],\n",
    "    lr_scheduler=cfg[\"training\"][\"lr_scheduler\"],\n",
    "    lr_warmup_epochs=cfg[\"training\"][\"lr_warmup_epochs\"],\n",
    "    log_every_n_epochs=cfg[\"dynamics\"][\"log_every_n_epochs\"],\n",
    "    device=DEVICE,\n",
    "    seed=SEED,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "torch.save(mil_model.state_dict(), \"mil_stage2.pt\")\n",
    "print(\"Stage 2 model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stage 3 — Joint Fine-tuning (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mil_model.unfreeze_encoder()\n",
    "\n",
    "dynamics_stage3 = train_mil(\n",
    "    mil_model,\n",
    "    tube_dataset,\n",
    "    n_epochs=cfg[\"training\"][\"stage3_epochs\"],\n",
    "    lr=cfg[\"training\"][\"lr\"] * 0.1,  # lower LR for fine-tuning\n",
    "    momentum=cfg[\"training\"][\"momentum\"],\n",
    "    log_every_n_epochs=cfg[\"dynamics\"][\"log_every_n_epochs\"],\n",
    "    device=DEVICE,\n",
    "    seed=SEED,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "torch.save(mil_model.state_dict(), \"mil_stage3.pt\")\n",
    "print(\"Stage 3 model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dynamics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Stage 2 dynamics for primary analysis (encoder frozen = cleaner dynamics)\n",
    "donor_traj = aggregate_to_donor_level(dynamics_stage2[\"records\"])\n",
    "\n",
    "# Learnability ranking (exclude PBS from biological interpretation)\n",
    "learnability_result = rank_cytokines_by_learnability(donor_traj, exclude=[\"PBS\"])\n",
    "ranking = learnability_result[\"ranking\"]\n",
    "\n",
    "print(\"Cytokine learnability ranking\")\n",
    "print(f\"Metric: {learnability_result['metric_description']}\")\n",
    "print()\n",
    "for i, (cyt, auc) in enumerate(ranking, 1):\n",
    "    print(f\"  {i:2d}. {cyt:20s}  AUC(mean_donor_p_correct_trajectory) = {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves for top-10 and bottom-10 cytokines\n",
    "top10 = [r[0] for r in ranking[:10]]\n",
    "bot10 = [r[0] for r in ranking[-10:]]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "for ax, group, group_label in zip(\n",
    "    axes,\n",
    "    [top10, bot10],\n",
    "    [\"Top-10 (highest AUC — learned earliest)\", \"Bottom-10 (lowest AUC — learned latest)\"],\n",
    "):\n",
    "    for cyt in group:\n",
    "        donor_curves = list(donor_traj[cyt].values())\n",
    "        mean_curve = np.mean(donor_curves, axis=0)\n",
    "        epochs = dynamics_stage2[\"logged_epochs\"]\n",
    "        ax.plot(epochs, mean_curve, label=cyt, alpha=0.8)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"P(Y_correct | t) — softmax probability of correct cytokine class\")\n",
    "    ax.set_title(group_label)\n",
    "    ax.legend(fontsize=7, ncol=2)\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Stage 2 learning curves\\n\"\n",
    "    \"Metric: mean p_correct_trajectory(t), aggregated to donor level \"\n",
    "    \"(median across pseudo-tubes per donor, then mean across donors)\",\n",
    "    fontsize=9,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"learning_curves.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention entropy summary\n",
    "entropy_result = compute_cytokine_entropy_summary(dynamics_stage2[\"records\"])\n",
    "entropy_summary = entropy_result[\"summary\"]\n",
    "\n",
    "# Sort by mean entropy (low=focused, high=pleiotropic)\n",
    "entropy_sorted = sorted(entropy_summary.items(), key=lambda x: x[1][\"mean_entropy\"])\n",
    "\n",
    "print(\"Cytokine attention entropy summary\")\n",
    "print(f\"Metric: {entropy_result['metric_description']}\")\n",
    "print()\n",
    "for cyt, stats in entropy_sorted:\n",
    "    print(f\"  {cyt:20s}  mean_entropy = {stats['mean_entropy']:.3f}  std = {stats['std_entropy']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion entropy summary\n",
    "confusion_result = compute_confusion_entropy_summary(\n",
    "    dynamics_stage2[\"confusion_entropy_trajectory\"], exclude=[\"PBS\"]\n",
    ")\n",
    "\n",
    "print(\"Cytokine confusion entropy ranking\")\n",
    "print(f\"Metric: {confusion_result['metric_description']}\")\n",
    "print()\n",
    "for cyt, auc in confusion_result[\"ranking\"]:\n",
    "    print(f\"  {cyt:20s}  AUC(confusion_entropy_trajectory) = {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with multiple seeds to assess stability. See config random_seeds.\n"
     ]
    }
   ],
   "source": [
    "# Seed stability — run with all three seeds from config\n",
    "# NOTE: Pre-register your directional predictions BEFORE looking at these results.\n",
    "\n",
    "all_dynamics = [dynamics_stage2]  # Add dynamics from other seeds here\n",
    "\n",
    "# Example: to run with additional seeds, re-run train_mil with seed=123 and seed=7\n",
    "# and append to all_dynamics.\n",
    "\n",
    "if len(all_dynamics) > 1:\n",
    "    stability = check_seed_stability(all_dynamics, exclude=[\"PBS\"])\n",
    "    print(f\"Mean Spearman rho across seeds: {stability['mean_rho']:.3f}\")\n",
    "    print(f\"Stable ordering: {stability['stable']}\")\n",
    "else:\n",
    "    print(\"Run with multiple seeds to assess stability. See config random_seeds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IL-2_IL-15_family:\n",
      "  members_found: ['IL-2', 'IL-15']\n",
      "  within_auc_std: 2.9490238849151282\n",
      "  between_auc_std: 13.025140774941931\n",
      "  passes: True\n",
      "\n",
      "type_I_IFN:\n",
      "  error: fewer than 2 members found: ['IFN-beta']\n"
     ]
    }
   ],
   "source": [
    "# Known functional groupings (IL-2 / IL-15 should be similar)\n",
    "known_groups = {\n",
    "    \"IL-2_IL-15_family\": [\"IL-2\", \"IL-15\"],\n",
    "    \"type_I_IFN\": [\"IFN-alpha\", \"IFN-beta\"],  # adjust to actual cytokine names\n",
    "}\n",
    "\n",
    "grouping_result = check_functional_groupings(donor_traj, known_groups)\n",
    "for group, result in grouping_result.items():\n",
    "    print(f\"\\n{group}:\")\n",
    "    for k, v in result.items():\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donor_traj_s3 = aggregate_to_donor_level(dynamics_stage3[\"records\"])\n",
    "result_s3 = rank_cytokines_by_learnability(donor_traj_s3, exclude=[\"PBS\"])\n",
    "ranking_s3 = result_s3[\"ranking\"]\n",
    "\n",
    "from cytokine_mil.analysis.validation import check_seed_stability\n",
    "# Reuse seed stability check to compare two orderings (Stage 2 vs Stage 3)\n",
    "stability_s2_s3 = check_seed_stability(\n",
    "    [dynamics_stage2, dynamics_stage3], exclude=[\"PBS\"]\n",
    ")\n",
    "print(\"Stage 2 vs Stage 3 ranking correlation\")\n",
    "print(\n",
    "    \"Metric: Spearman rho between cytokine learnability rankings \"\n",
    "    \"(AUC of donor-level p_correct_trajectory, median per donor, mean across donors)\"\n",
    ")\n",
    "print(f\"  Spearman rho = {stability_s2_s3['mean_rho']:.3f}\")\n",
    "print(f\"  Stable across stages (rho > 0.7): {stability_s2_s3['stable']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_traj_s3 = aggregate_to_donor_level(dynamics_stage3[\"records\"])\n",
    "ranking_s3 = rank_cytokines_by_learnability(donor_traj_s3, exclude=[\"PBS\"])\n",
    "\n",
    "from cytokine_mil.analysis.validation import check_seed_stability\n",
    "# Reuse seed stability to compare two orderings (Stage 2 vs 3)\n",
    "stability_s2_s3 = check_seed_stability(\n",
    "    [dynamics_stage2, dynamics_stage3], exclude=[\"PBS\"]\n",
    ")\n",
    "print(f\"Stage2 vs Stage3 ranking correlation: {stability_s2_s3['mean_rho']:.3f}\")\n",
    "print(f\"Stable across stages: {stability_s2_s3['stable']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (biovenv)",
   "language": "python",
   "name": "biovenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
