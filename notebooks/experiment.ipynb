{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cytokine Signaling Cascade Mapping via AB-MIL Dynamics\n",
    "\n",
    "This notebook runs the full experiment:\n",
    "1. Load config and data\n",
    "2. Stage 1 — pre-train the InstanceEncoder with cell-type supervision\n",
    "3. Stage 2 — train full AB-MIL (encoder frozen)\n",
    "4. Stage 3 (optional) — fine-tune jointly\n",
    "5. Dynamics analysis — learnability ranking, entropy, instance confidence\n",
    "6. Validation — seed stability, known-group checks\n",
    "\n",
    "Connect to the cluster kernel before running.\n",
    "All paths in `configs/default.yaml` point to cluster storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from cytokine_mil.data.label_encoder import CytokineLabel\n",
    "from cytokine_mil.data.dataset import PseudoTubeDataset, CellDataset\n",
    "from cytokine_mil.models.instance_encoder import InstanceEncoder\n",
    "from cytokine_mil.models.attention import AttentionModule\n",
    "from cytokine_mil.models.bag_classifier import BagClassifier\n",
    "from cytokine_mil.models.cytokine_abmil import CytokineABMIL\n",
    "from cytokine_mil.training.train_encoder import train_encoder\n",
    "from cytokine_mil.training.train_mil import train_mil\n",
    "from cytokine_mil.analysis.dynamics import (\n",
    "    aggregate_to_donor_level,\n",
    "    rank_cytokines_by_learnability,\n",
    "    compute_cytokine_entropy_summary,\n",
    ")\n",
    "from cytokine_mil.analysis.validation import (\n",
    "    check_seed_stability,\n",
    "    check_functional_groupings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Seed: 42\n"
     ]
    }
   ],
   "source": [
    "# --- Config ---\n",
    "with open(\"cytokines/cytokines-mil/configs/default.yaml\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = cfg[\"dynamics\"][\"random_seeds\"][0]\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest entries: 10920\n",
      "HVGs: 4000\n"
     ]
    }
   ],
   "source": [
    "MANIFEST_PATH = cfg[\"data\"][\"manifest_path\"]\n",
    "\n",
    "with open(MANIFEST_PATH) as f:\n",
    "    manifest = json.load(f)\n",
    "\n",
    "# Load HVG list (saved by preprocess_tubes.ipynb)\n",
    "HVG_PATH = str(Path(MANIFEST_PATH).parent / \"hvg_list.json\")\n",
    "with open(HVG_PATH) as f:\n",
    "    gene_names = json.load(f)\n",
    "\n",
    "print(f\"Manifest entries: {len(manifest)}\")\n",
    "print(f\"HVGs: {len(gene_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 91 (PBS at index 90)\n"
     ]
    }
   ],
   "source": [
    "# Label encoder — must be built once and saved for reproducibility\n",
    "LABEL_ENCODER_PATH = str(Path(MANIFEST_PATH).parent / \"label_encoder.json\")\n",
    "label_encoder = CytokineLabel().fit(manifest)\n",
    "label_encoder.save(LABEL_ENCODER_PATH)\n",
    "print(f\"Classes: {label_encoder.n_classes()} (PBS at index {label_encoder.encode('PBS')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from collections import defaultdict\n\n# Pseudo-tube dataset (Stage 2/3)\ntube_dataset = PseudoTubeDataset(MANIFEST_PATH, label_encoder, gene_names=gene_names)\nprint(f\"Tubes: {len(tube_dataset)}\")\n\n# --- Stage 1 manifest: one tube per cytokine, rotating donors ---\n# ~91 tubes × ~450 cells ≈ 40k cells ≈ 640 MB when preloaded.\n# Using the full 10k-tube manifest with shuffle=True would require\n# ~38 hours (random h5ad reads defeat the LRU cache).\n_cyt_to_entries: dict = defaultdict(list)\nfor _e in manifest:\n    if _e[\"tube_idx\"] == 0:\n        _cyt_to_entries[_e[\"cytokine\"]].append(_e)\n\n_stage1_manifest = []\nfor _i, _cyt in enumerate(sorted(_cyt_to_entries)):\n    _entries = sorted(_cyt_to_entries[_cyt], key=lambda e: e[\"donor\"])\n    _stage1_manifest.append(_entries[_i % len(_entries)])\n\nSTAGE1_MANIFEST_PATH = str(Path(MANIFEST_PATH).parent / \"manifest_stage1.json\")\nwith open(STAGE1_MANIFEST_PATH, \"w\") as f:\n    json.dump(_stage1_manifest, f)\n\n# preload=True: loads all tubes at init → in-memory shuffling, no disk I/O per batch\ncell_dataset = CellDataset(STAGE1_MANIFEST_PATH, gene_names=gene_names, preload=True)\nprint(f\"Cells: {len(cell_dataset)}\")\nprint(f\"Cell types: {cell_dataset.n_cell_types()}\")\n\ncell_loader = DataLoader(cell_dataset, batch_size=256, shuffle=True, num_workers=0)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stage 1 — Encoder Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/18619 [00:00<?, ?it/s]/cs/labs/mornitzan/yam.arieli/venvs/biovenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "                                                                                                      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m encoder = InstanceEncoder(\n\u001b[32m      2\u001b[39m     input_dim=\u001b[38;5;28mlen\u001b[39m(gene_names),\n\u001b[32m      3\u001b[39m     embed_dim=cfg[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33membedding_dim\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      4\u001b[39m     n_cell_types=cell_dataset.n_cell_types(),\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m encoder = \u001b[43mtrain_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcell_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstage1_epochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmomentum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m torch.save(encoder.state_dict(), \u001b[33m\"\u001b[39m\u001b[33mencoder_stage1.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEncoder saved.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/biovenv/lib/python3.11/site-packages/cytokine_mil/training/train_encoder.py:54\u001b[39m, in \u001b[36mtrain_encoder\u001b[39m\u001b[34m(encoder, dataloader, n_epochs, lr, momentum, device, verbose)\u001b[39m\n\u001b[32m     51\u001b[39m optimizer = torch.optim.SGD(encoder.parameters(), lr=lr, momentum=momentum)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, n_epochs + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     epoch_loss, n_correct, n_total = \u001b[43m_run_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m     58\u001b[39m         acc = n_correct / \u001b[38;5;28mmax\u001b[39m(n_total, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/biovenv/lib/python3.11/site-packages/cytokine_mil/training/train_encoder.py:80\u001b[39m, in \u001b[36m_run_epoch\u001b[39m\u001b[34m(encoder, dataloader, optimizer, criterion, device)\u001b[39m\n\u001b[32m     77\u001b[39m n_correct = \u001b[32m0\u001b[39m\n\u001b[32m     78\u001b[39m n_total = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/biovenv/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/biovenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/biovenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1448\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1445\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data)\n\u001b[32m   1447\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1449\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1451\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/biovenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1412\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1408\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1409\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1411\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1412\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1413\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1414\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/biovenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1243\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1230\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1231\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1232\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1240\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1241\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1242\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1244\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1245\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1246\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1247\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1248\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/multiprocessing/queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    112\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/multiprocessing/connection.py:256\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/multiprocessing/connection.py:423\u001b[39m, in \u001b[36mConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m     r = \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/multiprocessing/connection.py:930\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m    927\u001b[39m     deadline = time.monotonic() + timeout\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m     ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[32m    932\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [key.fileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28mself\u001b[39m._selector.poll(timeout)\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "encoder = InstanceEncoder(\n",
    "    input_dim=len(gene_names),\n",
    "    embed_dim=cfg[\"model\"][\"embedding_dim\"],\n",
    "    n_cell_types=cell_dataset.n_cell_types(),\n",
    ")\n",
    "\n",
    "encoder = train_encoder(\n",
    "    encoder,\n",
    "    cell_loader,\n",
    "    n_epochs=cfg[\"training\"][\"stage1_epochs\"],\n",
    "    lr=cfg[\"training\"][\"lr\"],\n",
    "    momentum=cfg[\"training\"][\"momentum\"],\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "torch.save(encoder.state_dict(), \"encoder_stage1.pt\")\n",
    "print(\"Encoder saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stage 2 — MIL Training (encoder frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = AttentionModule(\n",
    "    embed_dim=cfg[\"model\"][\"embedding_dim\"],\n",
    "    attention_hidden_dim=cfg[\"model\"][\"attention_hidden_dim\"],\n",
    ")\n",
    "classifier = BagClassifier(\n",
    "    embed_dim=cfg[\"model\"][\"embedding_dim\"],\n",
    "    n_classes=cfg[\"model\"][\"n_classes\"],\n",
    ")\n",
    "mil_model = CytokineABMIL(encoder, attention, classifier, encoder_frozen=True)\n",
    "\n",
    "dynamics_stage2 = train_mil(\n",
    "    mil_model,\n",
    "    tube_dataset,\n",
    "    n_epochs=cfg[\"training\"][\"stage2_epochs\"],\n",
    "    lr=cfg[\"training\"][\"lr\"],\n",
    "    momentum=cfg[\"training\"][\"momentum\"],\n",
    "    lr_scheduler=cfg[\"training\"][\"lr_scheduler\"],\n",
    "    lr_warmup_epochs=cfg[\"training\"][\"lr_warmup_epochs\"],\n",
    "    log_every_n_epochs=cfg[\"dynamics\"][\"log_every_n_epochs\"],\n",
    "    device=DEVICE,\n",
    "    seed=SEED,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "torch.save(mil_model.state_dict(), \"mil_stage2.pt\")\n",
    "print(\"Stage 2 model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stage 3 — Joint Fine-tuning (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mil_model.unfreeze_encoder()\n",
    "\n",
    "dynamics_stage3 = train_mil(\n",
    "    mil_model,\n",
    "    tube_dataset,\n",
    "    n_epochs=cfg[\"training\"][\"stage3_epochs\"],\n",
    "    lr=cfg[\"training\"][\"lr\"] * 0.1,  # lower LR for fine-tuning\n",
    "    momentum=cfg[\"training\"][\"momentum\"],\n",
    "    log_every_n_epochs=cfg[\"dynamics\"][\"log_every_n_epochs\"],\n",
    "    device=DEVICE,\n",
    "    seed=SEED,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "torch.save(mil_model.state_dict(), \"mil_stage3.pt\")\n",
    "print(\"Stage 3 model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dynamics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Stage 2 dynamics for primary analysis (encoder frozen = cleaner dynamics)\n",
    "donor_traj = aggregate_to_donor_level(dynamics_stage2[\"records\"])\n",
    "\n",
    "# Learnability ranking (exclude PBS from biological interpretation)\n",
    "ranking = rank_cytokines_by_learnability(donor_traj, exclude=[\"PBS\"])\n",
    "\n",
    "print(\"Cytokine learnability ranking (highest AUC = learned earliest):\")\n",
    "for i, (cyt, auc) in enumerate(ranking, 1):\n",
    "    print(f\"  {i:2d}. {cyt:20s}  AUC={auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves for top-10 and bottom-10 cytokines\n",
    "top10 = [r[0] for r in ranking[:10]]\n",
    "bot10 = [r[0] for r in ranking[-10:]]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "for ax, group, title in zip(axes, [top10, bot10], [\"Top-10 (earliest)\", \"Bottom-10 (latest)\"]):\n",
    "    for cyt in group:\n",
    "        # Mean across donors\n",
    "        donor_curves = list(donor_traj[cyt].values())\n",
    "        mean_curve = np.mean(donor_curves, axis=0)\n",
    "        epochs = dynamics_stage2[\"logged_epochs\"]\n",
    "        ax.plot(epochs, mean_curve, label=cyt, alpha=0.8)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"P(Y_correct)\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend(fontsize=7, ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"learning_curves.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention entropy summary\n",
    "entropy_summary = compute_cytokine_entropy_summary(dynamics_stage2[\"records\"])\n",
    "\n",
    "# Sort by mean entropy\n",
    "entropy_sorted = sorted(entropy_summary.items(), key=lambda x: x[1][\"mean\"])\n",
    "\n",
    "print(\"Attention entropy (low=focused, high=pleiotropic):\")\n",
    "for cyt, stats in entropy_sorted:\n",
    "    print(f\"  {cyt:20s}  mean={stats['mean']:.3f}  std={stats['std']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed stability — run with all three seeds from config\n",
    "# NOTE: Pre-register your directional predictions BEFORE looking at these results.\n",
    "\n",
    "all_dynamics = [dynamics_stage2]  # Add dynamics from other seeds here\n",
    "\n",
    "# Example: to run with additional seeds, re-run train_mil with seed=123 and seed=7\n",
    "# and append to all_dynamics.\n",
    "\n",
    "if len(all_dynamics) > 1:\n",
    "    stability = check_seed_stability(all_dynamics, exclude=[\"PBS\"])\n",
    "    print(f\"Mean Spearman rho across seeds: {stability['mean_rho']:.3f}\")\n",
    "    print(f\"Stable ordering: {stability['stable']}\")\n",
    "else:\n",
    "    print(\"Run with multiple seeds to assess stability. See config random_seeds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Known functional groupings (IL-2 / IL-15 should be similar)\n",
    "known_groups = {\n",
    "    \"IL-2_IL-15_family\": [\"IL-2\", \"IL-15\"],\n",
    "    \"type_I_IFN\": [\"IFN-alpha\", \"IFN-beta\"],  # adjust to actual cytokine names\n",
    "}\n",
    "\n",
    "grouping_result = check_functional_groupings(donor_traj, known_groups)\n",
    "for group, result in grouping_result.items():\n",
    "    print(f\"\\n{group}:\")\n",
    "    for k, v in result.items():\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Stage 2 vs Stage 3 Comparison\n",
    "\n",
    "If the learnability ordering is stable across Stage 2 and Stage 3, this is\n",
    "evidence that the dynamics signal is robust to encoder fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_traj_s3 = aggregate_to_donor_level(dynamics_stage3[\"records\"])\n",
    "ranking_s3 = rank_cytokines_by_learnability(donor_traj_s3, exclude=[\"PBS\"])\n",
    "\n",
    "from cytokine_mil.analysis.validation import check_seed_stability\n",
    "# Reuse seed stability to compare two orderings (Stage 2 vs 3)\n",
    "stability_s2_s3 = check_seed_stability(\n",
    "    [dynamics_stage2, dynamics_stage3], exclude=[\"PBS\"]\n",
    ")\n",
    "print(f\"Stage2 vs Stage3 ranking correlation: {stability_s2_s3['mean_rho']:.3f}\")\n",
    "print(f\"Stable across stages: {stability_s2_s3['stable']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (biovenv)",
   "language": "python",
   "name": "biovenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}